{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "inputLanguage = \"german\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between: baby and mother 0.5963075757026672\n",
      "Similarity between: mother and baby 0.5963075757026672\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "inputLanguage = \"german\"\n",
    "nlp = spacy.load(\"en_core_web_md\") # pacy.load('en_core_web_sm')\n",
    "tokens = nlp(\"baby mother aaa acceptance accountabilty affordable airplanes atmosphere backlash backup bandaid benefit benefits business cancer carcinogenic cause co-operation? communication conflict? conflicts continuous coral corruption cost culpability damage data death democracy distraction durability easy effective effectiveness expensive faciliation fear fearful flooding floods frustrated funding future generations global governance? greed greenwashing health hope hopeful how implemented incomplete indecisiveness ineffective inequality inexpensive innovative instability involvement jobs knowledge leadership learning misinformation nervous optimism over-hasty panic peace pessimism photosynthesis pioneering planes poverty preservation proactive protests quickness rapidity regulation relieved repopulation research responsibility reversable? risks rules safeguards safer sai scalable sceptics short-termism smelly solution starvation stopping sulphur suspicious sustaniblity technologies temperature temporary timelag trust un uncertainty unknown unkown unsafe unsustainable untested volcanoes war wars waste weather weathering\")\n",
    "\n",
    "\n",
    "tokens_clean = []\n",
    "  \n",
    "# append() function to push\n",
    "# element in the stack\n",
    "for token in tokens:\n",
    "    if not token.is_oov:\n",
    "        tokens_clean.append(token)\n",
    "\n",
    "# print(tokens_clean)\n",
    "\n",
    "\n",
    "token1, token2 = tokens_clean[0], tokens_clean[1]\n",
    "\n",
    "print(\"Similarity between:\", token1, \"and\", token2, token1.similarity(token2))\n",
    "print(\"Similarity between:\", token2, \"and\", token1, token2.similarity(token1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like salty fries and hamburgers. <-> Fast food tastes very good. 0.7799485853415737\n",
      "salty fries <-> hamburgers 0.730462372303009\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
    "doc2 = nlp(\"Fast food tastes very good.\")\n",
    "\n",
    "# Similarity of two documents\n",
    "print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n",
    "# Similarity of tokens and spans\n",
    "french_fries = doc1[2:4]\n",
    "burgers = doc1[5]\n",
    "print(french_fries, \"<->\", burgers, french_fries.similarity(burgers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter two space-separated words\n",
      "dsffds False 0.0 True\n",
      "China True 6.7980704 False\n",
      "Russia True 6.9937716 False\n",
      "Germany True 7.046142 False\n",
      "Tibet True 6.937505 False\n",
      "Ukraine True 7.1372385 False\n",
      "Belarus True 7.1372385 False\n",
      "EconomyS False 0.0 True\n",
      "Similarity: 0.0\n",
      "tokens dsffds China Russia Germany Tibet Ukraine Belarus EconomyS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fenn\\AppData\\Local\\Temp\\ipykernel_18540\\34371951.py:17: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  print(\"Similarity:\", token1.similarity(token2))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.7980704"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "  \n",
    "print(\"Enter two space-separated words\")\n",
    "words = \"dsffds China Russia Germany Tibet Ukraine Belarus EconomyS\" # input()\n",
    "  \n",
    "tokens = nlp(words)\n",
    "  \n",
    "for token in tokens:\n",
    "    # Printing the following attributes of each token.\n",
    "    # text: the word string, has_vector: if it contains\n",
    "    # a vector representation in the model, \n",
    "    # vector_norm: the algebraic norm of the vector,\n",
    "    # is_oov: if the word is out of vocabulary.\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)\n",
    "  \n",
    "token1, token2 = tokens[0], tokens[1]\n",
    "print(\"Similarity:\", token1.similarity(token2))\n",
    "# print(\"vector:\", token2.vector)\n",
    "print(\"tokens\", tokens)\n",
    "\n",
    "\n",
    "token2.vector_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Das System kann die angegebene Datei nicht finden: '--ip=127.0.0.1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\DATEN\\PHD\\CAMtools_CAMapp\\workingON\\spacy.ipynb Cell 5\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/DATEN/PHD/CAMtools_CAMapp/workingON/spacy.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m working\u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mWORKING_DIRECTORY\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m/some/default\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/DATEN/PHD/CAMtools_CAMapp/workingON/spacy.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(sys\u001b[39m.\u001b[39margv) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m: working \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39margv[\u001b[39m1\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/DATEN/PHD/CAMtools_CAMapp/workingON/spacy.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m os\u001b[39m.\u001b[39;49mchdir( working )\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Das System kann die angegebene Datei nicht finden: '--ip=127.0.0.1'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between Love <-> Joy : 0.6281557083129883\n",
      "Similarity between Happiness <-> Joy : 0.7758305072784424\n",
      "Similarity between Joy <-> Love : 0.6281557083129883\n",
      "Similarity between Joy <-> Happiness : 0.7758305072784424\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg') #  en_core_web_lg\n",
    "words = \"Love Happiness War Russia China Joy\" # input()\n",
    "\n",
    "tokens = nlp(words)\n",
    "# use of range() to define a range of values\n",
    "values = range(len(tokens))\n",
    "\n",
    "for token in tokens:\n",
    "    for i in values:\n",
    "        if token.similarity(tokens[i]) > .6 and token.similarity(tokens[i]) != 1:\n",
    "            print(\"Similarity between\", token, \"<->\", tokens[i], \":\", token.similarity(tokens[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between Krebs <-> Angst : 0.360155314207077\n",
      "Similarity between Krebs <-> Pandemie : 0.4700985550880432\n",
      "Similarity between Krebs <-> Job : 0.1255747675895691\n",
      "Similarity between Angst <-> Krebs : 0.360155314207077\n",
      "Similarity between Angst <-> Pandemie : 0.3251305818557739\n",
      "Similarity between Angst <-> Job : 0.16999255120754242\n",
      "Similarity between Pandemie <-> Krebs : 0.4700985550880432\n",
      "Similarity between Pandemie <-> Angst : 0.3251305818557739\n",
      "Similarity between Pandemie <-> Job : 0.10394466668367386\n",
      "Similarity between Job <-> Krebs : 0.1255747675895691\n",
      "Similarity between Job <-> Angst : 0.16999255120754242\n",
      "Similarity between Job <-> Pandemie : 0.10394466668367386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fenn\\AppData\\Local\\Temp\\ipykernel_18540\\658885601.py:10: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  if token.similarity(tokens[i]) > .10 and token.similarity(tokens[i]) != 1:\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('de_core_news_md')\n",
    "words = \"Krebs Covid Covid-19 Angst Pandemie Job\"\n",
    "tokens = nlp(words)\n",
    "\n",
    "# use of range() to define a range of values\n",
    "values = range(len(tokens))\n",
    "\n",
    "for token in tokens:\n",
    "    for i in values:\n",
    "        if token.similarity(tokens[i]) > .01 and token.similarity(tokens[i]) != 1:\n",
    "            print(\"Similarity between\", token, \"<->\", tokens[i], \":\", token.similarity(tokens[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spacy_version': '3.2.4',\n",
       " 'location': 'C:\\\\Users\\\\fenn\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\spacy',\n",
       " 'platform': 'Windows-10-10.0.19045-SP0',\n",
       " 'python_version': '3.9.5',\n",
       " 'pipelines': {'en_core_web_sm': '3.2.0'}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like salty fries and hamburgers. <-> Fast food tastes very good. 0.7799485853415737\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")  # make sure to use larger package!\n",
    "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
    "doc2 = nlp(\"Fast food tastes very good.\")\n",
    "\n",
    "# Similarity of two documents\n",
    "print(doc1, \"<->\", doc2, doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    product  price\n",
      "0  computer    850\n",
      "1    tablet    200\n",
      "2   printer    150\n",
      "3    laptop   1300\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'product': ['computer', 'tablet', 'printer', 'laptop'],\n",
    "        'price': [850, 200, 150, 1300]\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(r'C:\\DATEN\\PHD\\CAMtools_CAMapp\\workingON\\export_dataframe.csv', index=False, header=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   baby    mother       aaa  acceptance  accountabilty  \\\n",
      "baby           1.000000  0.596308  0.099860    0.169264      -0.164651   \n",
      "mother         0.596308  1.000000 -0.029805    0.219223      -0.138247   \n",
      "aaa            0.099860 -0.029805  1.000000   -0.002770       0.071011   \n",
      "acceptance     0.169264  0.219223 -0.002770    1.000000       0.033193   \n",
      "accountabilty -0.164651 -0.138247  0.071011    0.033193       1.000000   \n",
      "...                 ...       ...       ...         ...            ...   \n",
      "war            0.213974  0.293308  0.024074    0.240151      -0.066736   \n",
      "wars           0.197368  0.167718  0.099099    0.143748      -0.062963   \n",
      "waste          0.209931  0.164538  0.036784    0.186059      -0.071983   \n",
      "weather        0.243523  0.198259  0.076337    0.104683      -0.144557   \n",
      "weathering     0.011714  0.011594  0.084750    0.071291       0.100641   \n",
      "\n",
      "               affordable  airplanes  atmosphere  backlash    backup  ...  \\\n",
      "baby             0.226798   0.201032    0.119040  0.105728  0.130917  ...   \n",
      "mother           0.113264   0.084624    0.151149  0.120743  0.090451  ...   \n",
      "aaa              0.206815   0.141401   -0.054784 -0.071514  0.151774  ...   \n",
      "acceptance       0.178926   0.111661    0.241127  0.334738  0.087723  ...   \n",
      "accountabilty   -0.086432  -0.014495   -0.056616  0.114956 -0.038174  ...   \n",
      "...                   ...        ...         ...       ...       ...  ...   \n",
      "war              0.086248   0.315623    0.203063  0.308802  0.089249  ...   \n",
      "wars             0.076174   0.285038    0.135719  0.309832  0.108570  ...   \n",
      "waste            0.233829   0.180438    0.286779  0.135258  0.206093  ...   \n",
      "weather          0.210695   0.254036    0.372178  0.113711  0.146196  ...   \n",
      "weathering       0.044378   0.149656    0.276399  0.202351 -0.001365  ...   \n",
      "\n",
      "                 unkown    unsafe  unsustainable  untested  volcanoes  \\\n",
      "baby           0.019168  0.167789       0.041654  0.061613   0.062122   \n",
      "mother         0.093892  0.165578       0.051980  0.055028   0.079537   \n",
      "aaa            0.115177  0.058985       0.066472 -0.003010   0.070435   \n",
      "acceptance     0.013957  0.197150       0.175974  0.169789  -0.076613   \n",
      "accountabilty  0.171303  0.037595       0.088880  0.054694  -0.043457   \n",
      "...                 ...       ...            ...       ...        ...   \n",
      "war            0.061502  0.172809       0.244235  0.150545   0.141941   \n",
      "wars           0.050977  0.141406       0.316167  0.099983   0.186713   \n",
      "waste         -0.004981  0.365389       0.350829  0.138049   0.138346   \n",
      "weather       -0.010227  0.236999       0.101753  0.013139   0.292577   \n",
      "weathering     0.090557  0.134080       0.182236  0.104661   0.345180   \n",
      "\n",
      "                    war      wars     waste   weather  weathering  \n",
      "baby           0.213974  0.197368  0.209931  0.243523    0.011714  \n",
      "mother         0.293308  0.167718  0.164538  0.198259    0.011594  \n",
      "aaa            0.024074  0.099099  0.036784  0.076337    0.084750  \n",
      "acceptance     0.240151  0.143748  0.186059  0.104683    0.071291  \n",
      "accountabilty -0.066736 -0.062963 -0.071983 -0.144557    0.100641  \n",
      "...                 ...       ...       ...       ...         ...  \n",
      "war            1.000000  0.791381  0.263305  0.216042    0.104856  \n",
      "wars           0.791381  1.000000  0.229410  0.135617    0.100839  \n",
      "waste          0.263305  0.229410  1.000000  0.195218    0.141270  \n",
      "weather        0.216042  0.135617  0.195218  1.000000    0.345802  \n",
      "weathering     0.104856  0.100839  0.141270  0.345802    1.000000  \n",
      "\n",
      "[128 rows x 128 columns]\n",
      "(128, 128)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "#inputLanguage = \"german\"\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "\n",
    "rawData = \"baby mother aaa acceptance accountabilty affordable airplanes atmosphere backlash backup bandaid benefit benefits business cancer carcinogenic cause co-operation? communication conflict? conflicts continuous coral corruption cost culpability damage data death democracy distraction durability easy effective effectiveness expensive faciliation fear fearful flooding floods frustrated funding future generations global governance? greed greenwashing health hope hopeful how implemented incomplete indecisiveness ineffective inequality inexpensive innovative instability involvement jobs knowledge leadership learning misinformation nervous optimism over-hasty panic peace pessimism photosynthesis pioneering planes poverty preservation proactive protests quickness rapidity regulation relieved repopulation research responsibility reversable? risks rules safeguards safer sai scalable sceptics short-termism smelly solution starvation stopping sulphur suspicious sustaniblity technologies temperature temporary timelag trust un uncertainty unknown unkown unsafe unsustainable untested volcanoes war wars waste weather weathering\"\n",
    "tokens = nlp(rawData)\n",
    "\n",
    "##cleans up data olny for concepts in the model\n",
    "# Defined as a function to be used on multiple datasets if necessary \n",
    "def cleanData(data):\n",
    "    cleanTokens = []\n",
    "    for token in tokens:\n",
    "        if not token.is_oov:\n",
    "            cleanTokens.append(token) \n",
    "    return cleanTokens\n",
    "\n",
    "## Creates a matrix of word similarities\n",
    "def calcDistanceMatrix(cleanTokens):\n",
    "    df = pd.DataFrame(columns=cleanTokens, index = cleanTokens) # builds al empty pandas dataframe with rows and columns named after the words to be analyzed\n",
    "    for token in cleanTokens:\n",
    "        similiarities = []\n",
    "        for token2 in cleanTokens:\n",
    "            similiarities.append(token.similarity(token2))\n",
    "        df[token] = similiarities\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "cleanTokens = cleanData(tokens)\n",
    "print(calcDistanceMatrix(cleanTokens))\n",
    "print(calcDistanceMatrix(cleanTokens).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
