{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get current working directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputLanguage = \"english\"\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "LOADFILE = \"C:\\\\Users\\\\fenn\\Desktop\\\\tryPython\\\\summarizedWords.txt\"\n",
    "SAVEFILE = \"C:\\\\Users\\\\fenn\\Desktop\\\\tryPython\\\\distanceMatrix.txt\"  # change according to your needs\n",
    "#print(pd.read_csv(LOADFILE, delimiter=\"\\t\").iloc[:, 0])  # for debug"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "[death, depressing, doctors, family, illness, isolating, masks, nurses, online, schadenfreude, school, unity, vaccines]\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "rawData = pd.read_csv(LOADFILE, delimiter=\"\\t\").iloc[:, 0].str.cat(others=None, sep=\" \", na_rep=None, join='left') # reads in the file specified by LOADFILE, converting it to a single string of words separated by a blankspace\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tokens = nlp(rawData)\n",
    "print(len(tokens))\n",
    "##cleans up data olny for concepts in the model\n",
    "# Defined as a function to be used on multiple datasets if necessary \n",
    "def cleanData(data):\n",
    "    cleanTokens = []\n",
    "    for token in tokens:\n",
    "        if not token.is_oov:\n",
    "            cleanTokens.append(token) \n",
    "    return cleanTokens\n",
    "\n",
    "cleanTokens = cleanData(tokens)\n",
    "print(cleanTokens)\n",
    "print(len(cleanTokens))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### determining string distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creates a matrix of word similarities\n",
    "def calcDistanceMatrix(cleanTokens):\n",
    "    df = pd.DataFrame(columns=cleanTokens, index = cleanTokens) # builds al empty pandas dataframe with rows and columns named after the words to be analyzed\n",
    "    for token in cleanTokens:\n",
    "        similiarities = []\n",
    "        for token2 in cleanTokens:\n",
    "            similiarities.append(token.similarity(token2))\n",
    "        df[token] = similiarities\n",
    "    return df\n",
    "\n",
    "distanceMatrixDF = calcDistanceMatrix(cleanTokens)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the Matrix (for testing/debug only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  death  depressing   doctors    family   illness  isolating  \\\n",
      "death          1.000000    0.287752  0.348554  0.467888  0.563667   0.108230   \n",
      "depressing     0.287752    1.000000  0.214725  0.149365  0.309884   0.311087   \n",
      "doctors        0.348554    0.214725  1.000000  0.283719  0.476576   0.152347   \n",
      "family         0.467888    0.149365  0.283719  1.000000  0.417526   0.129258   \n",
      "illness        0.563667    0.309884  0.476576  0.417526  1.000000   0.246815   \n",
      "isolating      0.108230    0.311087  0.152347  0.129258  0.246815   1.000000   \n",
      "masks          0.156536    0.164630  0.225946  0.130879  0.180651   0.199388   \n",
      "nurses         0.250109    0.175960  0.731566  0.261821  0.372514   0.087905   \n",
      "online         0.167354    0.102948  0.270098  0.209884  0.126636  -0.020078   \n",
      "schadenfreude  0.050577    0.261763  0.012100  0.030170  0.085093   0.044267   \n",
      "school         0.312326    0.192806  0.345913  0.403484  0.281400   0.022325   \n",
      "unity          0.248547    0.115070  0.121192  0.246118  0.183735   0.226647   \n",
      "vaccines       0.231582    0.078848  0.397710  0.175229  0.432335   0.230839   \n",
      "\n",
      "                  masks    nurses    online  schadenfreude    school  \\\n",
      "death          0.156536  0.250109  0.167354       0.050577  0.312326   \n",
      "depressing     0.164630  0.175960  0.102948       0.261763  0.192806   \n",
      "doctors        0.225946  0.731566  0.270098       0.012100  0.345913   \n",
      "family         0.130879  0.261821  0.209884       0.030170  0.403484   \n",
      "illness        0.180651  0.372514  0.126636       0.085093  0.281400   \n",
      "isolating      0.199388  0.087905 -0.020078       0.044267  0.022325   \n",
      "masks          1.000000  0.233056  0.057517      -0.030721  0.098334   \n",
      "nurses         0.233056  1.000000  0.186137       0.005113  0.396020   \n",
      "online         0.057517  0.186137  1.000000      -0.037977  0.300861   \n",
      "schadenfreude -0.030721  0.005113 -0.037977       1.000000 -0.029876   \n",
      "school         0.098334  0.396020  0.300861      -0.029876  1.000000   \n",
      "unity          0.161519  0.149980  0.027459       0.076974  0.168660   \n",
      "vaccines       0.164724  0.242207  0.055223      -0.029525  0.155215   \n",
      "\n",
      "                  unity  vaccines  \n",
      "death          0.248547  0.231582  \n",
      "depressing     0.115070  0.078848  \n",
      "doctors        0.121192  0.397710  \n",
      "family         0.246118  0.175229  \n",
      "illness        0.183735  0.432335  \n",
      "isolating      0.226647  0.230839  \n",
      "masks          0.161519  0.164724  \n",
      "nurses         0.149980  0.242207  \n",
      "online         0.027459  0.055223  \n",
      "schadenfreude  0.076974 -0.029525  \n",
      "school         0.168660  0.155215  \n",
      "unity          1.000000  0.020357  \n",
      "vaccines       0.020357  1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(distanceMatrixDF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting a .txt file to/with the location specified by the SAVEFILE variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export DataFrame to text file\n",
    "with open(SAVEFILE, 'w') as f:  # overwrites existing files of the same name and path. If you want to change that: change line to with open(SAVEFILE, 'x') as f:\n",
    "    distMatString = distanceMatrixDF.to_string(header=True, index=True)\n",
    "    f.write(distMatString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 383 ORG\n",
      "U.K. 27 31 384 GPE\n",
      "$1 billion 44 54 394 MONEY\n",
      "Apple 71 76 383 ORG\n",
      "New York 95 103 384 GPE\n",
      "Red Flag 105 113 383 ORG\n",
      "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion. I like apples. Apple is a big company. New York, Red Flag, I have a red flag.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label, ent.label_)\n",
    "\n",
    "print(nlp.get_pipe('ner').labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('she', 0.41524189710617065), ('when', 0.40957537293434143), ('he', 0.390671044588089), ('how', 0.38315147161483765), ('does', 0.37388527393341064), ('let', 0.37291908264160156), ('that', 0.3664986193180084), ('what', 0.3649815320968628), ('you', 0.3649410009384155), ('who', 0.36284059286117554), ('where', 0.36010709404945374), (\"n't\", 0.35870176553726196), ('they', 0.35863903164863586), ('why', 0.3551936447620392), ('can', 0.35339903831481934), ('ca', 0.3533383905887604), ('it', 0.3516964316368103), ('could', 0.34992530941963196), ('not', 0.34585222601890564), ('got', 0.3430679738521576), ('there', 0.34229207038879395), ('cause', 0.3414511978626251), ('should', 0.34123069047927856), ('is', 0.33961135149002075), ('would', 0.3353287875652313), ('might', 0.3347433805465698), ('need', 0.3323975205421448), ('wo', 0.3255627155303955), ('we', 0.32413962483406067), ('a', 0.3208402693271637), ('must', 0.31895139813423157), ('did', 0.3172534108161926), ('this', 0.31190353631973267), (\"'re\", 0.3117658197879791), ('do', 0.3102989196777344), ('or', 0.3087747097015381), ('have', 0.3071137070655823), ('cuz', 0.3067999482154846), (\"'ll\", 0.30324482917785645), ('i', 0.3029840290546417), ('and', 0.2966884970664978), ('was', 0.2951567769050598), ('may', 0.29439106583595276), ('has', 0.2941083312034607), ('had', 0.292054146528244), ('all', 0.29146644473075867), ('dare', 0.29134082794189453), ('those', 0.2892282009124756), ('ought', 0.28768447041511536), (\"'d\", 0.28297924995422363)]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def most_similar(word, topn=5):\n",
    "  word = nlp.vocab[str(word)]\n",
    "  queries = [\n",
    "      w for w in word.vocab \n",
    "      if w.is_lower == word.is_lower  and np.count_nonzero(w.vector)\n",
    "  ]\n",
    "\n",
    "  by_similarity = sorted(queries, key=lambda w: word.similarity(w), reverse=True)\n",
    "  return [(w.lower_,w.similarity(word)) for w in by_similarity[:topn+1] if w.lower_ != word.lower_]\n",
    "\n",
    "print(most_similar(\"dog\", topn=50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
